Index: hw3.tex
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>\\documentclass[12pt]{article}\r\n\\usepackage[utf8]{inputenc}\r\n\\usepackage{geometry}\r\n\\PassOptionsToPackage{usenames,dvipsnames}{color}  %% Allow color names\r\n\\usepackage[svgnames]{xcolor}\r\n\\usepackage{framed}        % enable shading\r\n\\usepackage[hyphens]{url}  % wrap urls across lines, breaking by hyphens\r\n\\usepackage{hyperref}\r\n\\usepackage{listings}\r\n\\usepackage{float}         % keep figures in order\r\n\\usepackage{graphicx}      % allow graphics/figures\r\n\\usepackage{sectsty}       % set section header font sizes\r\n\\usepackage[compact]{titlesec}  % set skip after sections\r\n\\usepackage{enumitem}\r\n\\usepackage{amssymb}\r\n\r\n\r\n\\geometry{margin=1in}\r\n\r\n% set up url\r\n\\hypersetup{\r\n    colorlinks=true,\r\n    linkcolor=blue,\r\n    filecolor=magenta,      \r\n    urlcolor=NavyBlue,\r\n}\r\n\r\n% color to shade with\r\n\\definecolor{shadecolor}{gray}{0.9}\r\n\\usepackage{tgpagella}\r\n\r\n %put box around figure captions\r\n\\makeatletter\r\n\\long\\def\\@makecaption#1#2{%\r\n  \\vskip\\abovecaptionskip\r\n  \\sbox\\@tempboxa{\\fbox{#1: #2}}%\r\n  \\ifdim \\wd\\@tempboxa >\\hsize\r\n    \\fbox{\\parbox{\\dimexpr\\linewidth-2\\fboxsep-2\\fboxrule}{#1: #2}}\\par\r\n  \\else\r\n    \\global \\@minipagefalse\r\n    \\hb@xt@\\hsize{\\hfil\\box\\@tempboxa\\hfil}%\r\n  \\fi\r\n  \\vskip\\belowcaptionskip}\r\n\\makeatother\r\n\r\n%no indent and modify distance between paragraphs\r\n\\setlength\\parindent{0pt}\r\n\\setlength\\parskip{12pt}\r\n\r\n% Reduce spacing after section headers\r\n\\titlespacing{\\section}{0pt}{*1}{*0}\r\n\\titlespacing{\\subsection}{0pt}{*1}{*0}\r\n\\titlespacing{\\subsubsection}{0pt}{*0}{*0}\r\n\r\n\r\n\\begin{document}\r\n\r\n\\begin{center}\r\n{\\Large \\textbf{CS 330 Autumn 2021/2022 Homework 3} \\\\ Few-Shot Learning with Pre-trained Language Models\r\n\\\\ \r\n\\vspace{0.2cm}\r\nDue Wednesday November 2nd, 11:59 PM PT}\r\n\r\n\\begin{tabular}{rl}\r\nSUNet ID: &  \\\\\r\nName: & \\\\\r\nCollaborators: & \r\n\\end{tabular}\r\n\\end{center}\r\n\r\nBy turning in this assignment, I agree by the Stanford honor code and declare that all of this is my own work.\r\n\r\n\\section*{Overview}\r\nThis assignment will explore several methods for performing few-shot (and zero-shot) learning with pre-trained language models (LMs), including variants of fine-tuning and in-context learning. The goal of this assignment is to gain familiarity with performing few-shot learning with pre-trained LMs, learn about the relative strengths and weaknesses of fine-tuning and in-context learning, and explore some recent methods proposed for improving on the basic form of these algorithms.\r\n\r\n\\noindent We have provided you with starter code, which can be downloaded from the course website.\r\n\r\n\\textbf{Submission:} To submit your homework, submit one PDF report to Gradescope containing written answers and Matplotlib plots (screenshots are acceptable) to the questions below, as well as \\texttt{ft.py} and \\texttt{icl.py} (files) in a single zip file. \\textbf{Do not modify any other files.} The PDF should also include your name and any students you talked to or collaborated with. \\textbf{Any written responses or plots to the questions below must appear in your PDF submission.}\r\n\r\n\\textbf{Setup:} This assignment requires using the HuggingFace library for loading pre-trained models and datasets. The required packages are provided in a \\texttt{requirements.txt} file to enable easy installation, which you can install using \\texttt{pip install -r requirements.txt}. If you have trouble installing on your laptop (e.g. some Apple Silicon machines), you can use your Azure instance to debug. If you're having trouble installing the requirements, you might need a specific CUDA version; checking the \\href{https://pytorch.org/get-started/locally/}{PyTorch install guide} might help find the right version.\r\n\r\n\\textbf{Code Overview:} The code consists of several files to enable fine-tuning and in-context learning. You are expected to write the code in the following files:\r\n\\begin{itemize}\r\n    \\item \\texttt{ft.py}: Fine-tuning script; you'll implement parameter selection, loss \\& accuracy calculation, the LoRA implementation (this will be explained in Q2!), fine-tuning batch tokenization, and the model update step.\r\n    \\item \\texttt{icl.py}: In-context learning script; you'll implement prompt assembly and model sampling.\r\n\\end{itemize}\r\n\r\nA detailed description for every function can be found in the comments. You are not expected to change any code except for sections marked with \\texttt{YOUR CODE HERE}.\r\n\r\n\\section*{Compute}\r\n\r\nFor this assignment, you will complete all sections on Azure instances with GPUs. Avoid using Azure for debugging; verify that your code runs without crashing on your own machine, and use Azure only once you think your code is finished.\r\n\r\nThe \\href{https://docs.google.com/document/d/10DZEFQA9qAZNMEGcrhsJ6fV_5IshbsCabMco1rKpleg/edit#}{CS330 Azure Guide} has instructions for setting up and accessing an Azure GPU spot instance.\r\n\r\n{\r\n\\begin{center}\r\n\\large\r\n    \\textbf{\\textit{Be sure to shut down your Azure instance when not in use!}}\r\n\\end{center} \r\n}\r\n\r\n\\section*{Datasets}\r\n\r\nYou'll explore three different language datasets in this assignment. The first, Amazon Reviews, is a classification dataset that you'll use for the warmup. The other two, XSum and bAbI, require generating open-ended language.\r\n\r\n\\begin{enumerate}\r\n    \\item For the fine-tuning warmup, we'll explore a simple text classification problem, a subset of the \\href{https://huggingface.co/datasets/amazon\\_us\\_reviews}{Amazon Reviews} dataset. The portion of the Amazon Reviews dataset that we will consider contains paired video reviews and star ratings; the task we will consider will be five-way classification of a review into the number of stars its corresponding rating gave, among \\texttt{\\{1,2,3,4,5\\}}. \\textbf{You can expect accuracy numbers \\textit{roughly} in the 0.2-0.4 range for Amazon Reviews in this assignment.}\r\n    \\item \\href{https://huggingface.co/datasets/xsum}{XSum}: The XSum dataset contains news articles from the BBC and corresponding one sentence summaries. The evaluation metric typically used for summarization is \\textbf{\\href{https://en.wikipedia.org/wiki/ROUGE_(metric)}{ROUGE} score}, which measures $n$-gram overlap between the target and prediction (how many words appear in both, how many bigrams, etc.). An \\href{https://en.wikipedia.org/wiki/N-gram#Examples}{$n$-gram} is a subsequence of $n$ consecutive words, in this context.  \\textbf{You can expect ROUGE scores \\textit{roughly} in the 0.1-0.3 range for XSum in this assignment.}\r\n    \\item \\href{https://research.facebook.com/downloads/babi/}{bAbI} is a AI benchmark suite developed by Facebook AI Research. The task that we will use is a question-answering task that requires reasoning about contextual information that may or may not be relevant to answer a question. A sample question from the dataset is:\r\n    \r\n    \\texttt{Mary went back to the office. John went to the bathroom. Where is Mary? In the office}\r\n    \r\n    \\textbf{You can expect accuracy numbers \\textit{roughly} in the 0.25-0.9 range for bAbI QA in this assignment.}\r\n\\end{enumerate}\r\n\r\nAll of these datasets are available through the HuggingFace library.\r\n\r\n\\section*{(10 pt) Question 0: Fine-tuning warmup}\r\nAs a warmup, we will perform perhaps the most straightforward form of $k$-shot learning with a pre-trained model: directly fine-tuning the entire model on the $k$ examples. We will use two different sizes of smaller BERT models that have been compressed through distillation.\\footnote{See \\href{https://arxiv.org/pdf/1908.08962.pdf}{here} to learn more about this class of distilled BERT models. For final projects involving language models, these smaller BERT models may be useful for performing compute-friendly experiments!}\r\n\r\n\\begin{enumerate}\r\n    \\item Implement the logic for fine-tuning, including selecting the parameters that will be fine-tuned (only the case for \\texttt{`all'} for this question) in \\texttt{ft.py:\\allowbreak parameters\\_to\\allowbreak \\_fine\\_tune()}, and computing the loss and accuracy in \\texttt{ft.py:\\allowbreak get\\_loss} and \\texttt{ft.py:\\allowbreak get\\_acc}. You only need to complete the loss/accuracy calculations under \\texttt{if logits.dim() == 2:} for this question.\r\n    \\item (8 pt) Run the command:\r\n    \r\n    {\\small\\texttt{python3 ft.py --task ft --model bert-tiny,bert-med --dataset amazon --k 1,8,128}}\r\n    \r\n    to fine-tune two sizes of BERT models on the Amazon Reviews dataset for various values of $k$. While debugging, you can pass only one value for each of the arguments to run only that subset, e.g. \\texttt{python3 ft.py --task ft --model bert-tiny --dataset amazon --k 1}.\r\n    \r\n    If you see a log message like \\texttt{Some weights of the model checkpoint...}, this is expected, since the pre-trained model does not contain a prediction head for our task (this is why we need to fine-tune!).\r\n\r\n    To plot your results, run the command:\r\n    \r\n    {\\small\\texttt{python3 ft.py --task plot --model bert-tiny,bert-med --dataset amazon --k 1,8,128}}\r\n    \r\n    In one sentence, what do you notice about the performance of the two model scales?\r\n    \r\n    \\textbf{\\color{red}Include your plot and answer here.}\r\n\r\n    \\item (1 pt) If we fine-tune the all of our model parameters for each task, we must save a new complete copy of the model's parameters for each new task. As an example, a BERT-mini model similar to the ones you just fine-tuned has approximately 11.2 million parameters; assuming parameters are represented as 4-byte floats, after fine-tuning on a new task, how much disk space do we need to store the new fine-tuned model parameters?\r\n\r\n    \\textbf{\\color{red} Write your answer here.}\r\n\r\n    \\item (1 pt) Google's recent large language model \\href{https://storage.googleapis.com/pathways-language-model/PaLM-paper.pdf}{PaLM} has 540 billion parameters. How much disk space would be needed to store a new fine-tuned version of this model, assuming parameters are represented as 4-byte floats?\r\n\r\n    \\textbf{\\color{red} Write your answer here.}\r\n\r\n\\end{enumerate}\r\n\r\n\\section*{(15 pt) Question 1: In-context learning}\r\nA surprising property of large language models is their emergent ability to learn \\textit{in-context}, that is, their ability to learn a task without updating any parameters at all. The name `in-context' comes from the fact that the learning is done by simply including several examples or a task description (or both!) prepended to a test input present to the model\r\n\r\nFor example, for a question-answering task, to make a 2-shot prediction for a test input `Why is the sky blue?', rather than presenting the input:\r\n\r\n\\texttt{Why is the sky blue?\\textless generate\\textgreater}\r\n\r\nwe would simply prepend our 2 examples to the input:\r\n\r\n\\texttt{Who is the US president? Joe Biden What is earth's tallest mountain? Mount... \\\\\r\nEverest Why is the sky blue?\\textless generate\\textgreater}\r\n\r\nIn addition to few-shot in-context learning, models can often improve their zero-shot generalization if the input is formatted in a particular manner; for example, adding a \\texttt{Q:} and \\texttt{A:} prefix to the input and label, respectively:\r\n\r\n\\texttt{Q: Why is the sky blue? A:\\textless generate\\textgreater}\r\n\r\nFinally, these two approaches can be combined, for example adding the \\texttt{Q:} and \\texttt{A:} markers to each example in the context as well as the test input.\r\n\r\n\\begin{enumerate}\r\n    \\item Complete the code for in-context learning in \\texttt{icl.py}.\r\n    \\begin{enumerate}\r\n        \\item Implement prompt creation for the XSum and bAbI tasks, which is found in \\texttt{icl.py:get\\_icl\\_prompts()}. You will implement 4 prompt format modes:\r\n        \\begin{enumerate}\r\n            \\item \\texttt{qa} \\textbf{[only for bAbI]}: Add ``\\texttt{ In the }'' after the question (including the final test question that we want to generate an answer for!) and before each answer, since this task involves answering questions about the physical whereabouts of a person. In addition, add a period after the answer (omitting the period can significantly impact your results!). Be sure to include a space between the question and \\texttt{In the}, as well as a space before the answer (though keep in mind Note 1!). Note the  \\texttt{Q:} and \\texttt{A:} prompts in the example earlier don't apply here.\r\n            \\item \\texttt{none} \\textbf{[only for XSum]}: In this case, we use the raw $k$ examples without any additional formatting; that is, we just concatenate $[x_1; y_1; ... ; \\allowbreak x_k; y_k; x^*]$ with a space between each element (but no space at the end), where $x^*$ is the input that we want to generate an answer for.\r\n            \\item \\texttt{tldr} \\textbf{[only for XSum]}: Add the text ``\\texttt{ TL;DR: }'' after each article/input (including the final test article) and before the summary/target.\r\n            \\item \\texttt{custom} \\textbf{[only for XSum]}: Come up with your own prompt format for article summarization (different from the ones we've shown!).\r\n        \\end{enumerate}\r\n        In general, the idea of in-context learning is to format the support examples in the same way as the test example, to leverage the model's tendency toward imitation.\r\n\r\n        \\textbf{Note 1: Due to a quirk with GPT-2 tokenization, you should not include a space at the end of your prompt before generation.}\r\n        \r\n        \\textbf{Note 2: Be sure to shuffle the order of the support inputs/targets when you construct the prompt (we will need this randomization later).}\r\n        \\item Implement greedy sampling in \\texttt{icl.py:do\\_sample()}. The GPT-2 models used in this and the following questions use an autoregressive factorization of the probability of a sequence, i.e. $p_\\theta(\\mathbf{x}) = \\prod_t p_\\theta(x_t|x_{<t})$. `Greedy' sampling means that given a context $x_{<t}$ producing a distribution over next tokens $p_\\theta(x_t|x_{<t})$, we deterministically choose the next token $x_t$ to be the token with highest probability.\r\n        \r\n        \\textbf{Note 3: Be sure you understand what each dimension of the model's output \\texttt{logits} represents. Misinterpreting the dimensions of this output can lead to subtle bugs.}\r\n        \r\n        \\item Finally, put the pieces together by completing the implementation of \\texttt{icl.py:\\allowbreak run\\_icl()}, using your \\texttt{get\\_icl\\_prompts()} and \\texttt{do\\_sample()} functions, as well as the HuggingFace tokenizer defined in the loop. \\\\ \\emph{Hint}: Your solution here should be less than 5 lines of code.\r\n    \\end{enumerate}\r\n\r\n    \\item (10 pt) First, evaluate $k$-shot in-context performance on bAbI for GPT-2-medium (355M parameters) and full-size GPT-2 (1.5B parameters) for various values of $k$ with the command:\r\n    \r\n    \\texttt{\\small python3 icl.py --task icl --model med,full --dataset babi --k 0,1,16}\r\n    \r\n    Plot the results with the command:\r\n    \r\n    \\texttt{\\small python3 icl.py --task plot --model med,full --dataset babi --k 0,1,16}\r\n    \r\n    What relationship(s) do you notice between model scale and few-shot performance?\r\n        \r\n    \\textbf{\\color{red}Include your plot and answer here.}\r\n\r\n    \\item (5 pt) Now let's evaluate several different prompt formats on the XSum dataset. With and without a task description in the prompt, evaluate zero-shot and few-shot performance for XSum on GPT-2-Medium with the command:\r\n\r\n    \\texttt{\\small python3 icl.py --task icl --model med,full --dataset xsum --k 0,1,4 \\textbackslash \\\\\r\n    \\phantom{asdf}--prompt none,tldr,custom}\r\n    \r\n    Note that we use much smaller $k$ than in the previous problem, because we must fit all $k$ examples into the model's context window, which is only 1024 tokens. The fixed context window length is one limitation of in-context learning.\r\n    \r\n    \\textbf{The $k=4$ XSum evaluation on full-size GPT-2 may take approximately 40 minutes on your Azure instance for each prompt mode}; this is expected, and is another downside of in-context learning (we need to process a much longer input, containing the prompt, compared to a fine-tuned model that just processes the test input).\r\n    \r\n    Plot the zero-shot and few-shot performance of GPT-2 on XSum:\r\n    \r\n    \\texttt{\\small python3 icl.py --task plot --model med,full --dataset xsum --k 0,1,4 \\textbackslash \\\\\r\n    \\phantom{asdf}--prompt none,tldr,custom}\r\n    \r\n    How does the performance of the \\texttt{TL;DR:} prompt compare with no prompt formatting? What was your custom prompt format, and how did it compare with \\texttt{TL;DR:}? Discuss the relative performance of the different prompts in the zero-shot, one-shot, and few-shot settings.\r\n    \r\n    \\textbf{\\color{red}Include your plot and answer here.}\r\n\r\n\\end{enumerate}\r\n\r\n\\section*{(15 pt) Question 2: Parameter-efficient fine-tuning}\r\nAs we observed in question 1, fine-tuning the entire model can become extremely costly for very large models. In this question, we'll explore more methods for \\textit{parameter-efficient fine-tuning}, i.e., methods that enable fine-tuning while creating fewer new parameters and are less prone to overfitting.\r\n\\begin{enumerate}\r\n    \\item Finish the implementation for each version of parameter-efficient fine-tuning for GPT-2-Medium in \\texttt{ft.py:parameters\\_to\\_fine\\_tune()}:\r\n    \\begin{enumerate}\r\n        \\item \\texttt{last}: Fine-tune only the last 2 transformer blocks\r\n        \\item \\texttt{first}: Fine-tune only first 2 transformer blocks\r\n        \\item \\texttt{middle}: Fine-tune only middle 2 transformer blocks\r\n    \\end{enumerate}\r\n    This step simply requires selecting the correct subset of parameters for each version listed above in \\texttt{parameters\\_to\\_fine\\_tune()}. Keep in mind you should be returning an iterable of \\texttt{nn.Parameter} here, not \\texttt{nn.Module}.\r\n\r\n    \\item In addition to selecting only a subset of layers to fine-tune, more sophisticated methods for parameter-efficient fine-tuning exist; one such method is \\href{https://arxiv.org/pdf/2106.09685.pdf}{LoRA: Low-rank adaptation}. For each layer $\\ell$ in the network, rather than fine-tune the pre-trained weight matrix $W_\\ell^0 \\in \\mathbb{R}^{d_1\\times d_2}$ into an arbitrary new weight matrix $W_\\ell^{ft}$, LoRA constrains the space of fine-tuned parameters such that $W_\\ell^{ft} = W_\\ell^0 + AB^\\top$, where $A \\in \\mathbb{R}^{d_1\\times p}$ and $B \\in \\mathbb{R}^{d_2\\times p}$, and $p << d_1,d_2$. That is, we force the \\textit{difference} between $W_\\ell^0$ and $W_\\ell^{ft}$ to be rank $p$, keeping $W_\\ell^0$ frozen and only fine-tuning the rank-$p$ residual matrix $AB^\\top$. We will apply this form of fine-tuning to both the MLP weight matrices and the self-attention weight matrices in the model.\r\n    \\begin{enumerate}\r\n        \\item For a single layer, what are the parameter savings we achieve by using LoRA? i.e., what is the ratio of parameters fine-tuned by LoRA (for arbitrary $p$) to the number of parameters in $W_\\ell^0$? In terms of $p,d_1,d_2$, when will LoRA provide the greatest savings in newly-created parameters?\r\n        \\item Finish the \\texttt{LoRAConv1DWrapper} in \\texttt{ft.py}, which wraps a pre-trained Conv1D layer with LoRA parameters. Conv1D is equivalent to a Linear layer; it's a 1D conv because we apply the same linear transform at each time step of the sequence. You can extract the shape of the pre-trained weight matrix from the \\texttt{base\\_module.weight.shape} tuple. You don't need to worry about biases here, just the low-rank weight matrix residual.\r\n        \r\n        \\item Add the corresponding logic for LoRA in \\texttt{ft.py:parameters\\_to\\_fine\\_tune()}. Hint: consider using the \\texttt{.modules()} function of \\texttt{nn.Module} and checking for modules that are an instance of \\texttt{LoRAConv1DWrapper}.\r\n        \\item Implement the 3-dim version of the loss and accuracy in \\texttt{ft.py:get\\_loss()} and \\texttt{ft.py:get\\_acc()}.\r\n        \\item Implement batch construction for fine-tuning GPT-2 in function \\texttt{ft.py:\\allowbreak tokenize\\_\\allowbreak gpt2\\_batch()}. Read the instructions in the code carefully!\r\n        \\item Finally, put it all together by filling out the logic for one step of training in \\texttt{ft.py:ft\\_gpt2()}. Note that we use \\textit{gradient accumulation}, meaning that accumulate gradients over \\texttt{grad\\_accum} steps, and only update our model's parameters after each \\texttt{grad\\_accum} steps.\r\n    \\end{enumerate}\r\n    \r\n    \\item (15 pt) Run fine-tuning for each parameter-efficient fine-tuning method, using $p=4,16$ for LoRA (so, 5 variants in total); run the commands:\r\n\r\n    {\\small \\texttt{python3 ft.py --task ft --model med --mode first,last,middle,lora4,lora16 \\textbackslash \\\\\r\n    \\phantom{asdf}--dataset xsum,babi --k 0,1,8,128}}\r\n\r\n    Plot \\textbf{k-shot performance} as \\textbf{k is varied} for GPT-2-medium, one plot for each dataset; run the commands:\r\n\r\n    {\\small \\texttt{python3 ft.py --task plot --model med --mode first,last,middle,lora4,lora16 \\textbackslash \\\\\r\n    \\phantom{asdf}--dataset xsum --k 0,1,8,128}}\r\n\r\n    {\\small \\texttt{python3 ft.py --task plot --model med --mode first,last,middle,lora4,lora16 \\textbackslash \\\\\r\n    \\phantom{asdf}--dataset babi --k 0,1,8,128}}\r\n    \r\n    \\textbf{\\color{red}Include your plots and describe the results here.}\r\n\r\n\\end{enumerate}\r\n\r\n\\section*{(10 pt) Question 3: Comparing in-context learning and fine-tuning}\r\n\r\n\\begin{enumerate}\r\n    \\item (5 pt) Plot the few-shot performance of LoRA-16 and in-context learning for XSum in the same plot with the command:\r\n\r\n    {\\small\\texttt{python3 q3\\_plot.py}}\r\n\r\n    When does in-context learning seem like the better choice, with respect to the amount of data available? What about fine-tuning? What limitation of in-context learning does this result highlight?\r\n    \r\n    \\textbf{\\color{red}Include your plot and write your answer here.}\r\n\r\n    \\item (5 pt) One potential disadvantage of in-context learning is that we must choose an ordering for the examples in our prompt, and \\textit{that ordering can sometimes impact performance negatively}. Run the command:\r\n\r\n    {\\small \\texttt{python3 icl.py --task icl --model med --dataset babi --k 16 --repeats 5}}\r\n\r\n    to compute the evaluation performance of in-context few-shot performance for 5 random orderings of the prompt. Report the number you get; the standard deviation of performance for fine-tuning is approximately 0.013. Does in-context learning or fine-tuning have a higher standard deviation?\r\n    \r\n    \\textbf{\\color{red}Write your answer here.}\r\n\r\n    \\textbf{(5 pt) Extra credit:} See \\href{https://arxiv.org/pdf/2104.08786.pdf}{this paper} for multiple heuristics for picking a prompt ordering. Implement either the globalE or localE heuristic, and report the accuracy you find for that ordering for 16-shot bAbI on GPT-2-medium. Compare it with the accuracy you found with random prompt orderings in question 1.\r\n    \r\n    \\textbf{\\color{red}Write your answer here.}\r\n\\end{enumerate}\r\n\r\n\r\n\\end{document}\r\n\r\n\r\n
===================================================================
diff --git a/hw3.tex b/hw3.tex
--- a/hw3.tex	
+++ b/hw3.tex	
@@ -63,7 +63,7 @@
 
 \begin{tabular}{rl}
 SUNet ID: &  \\
-Name: & \\
+Name: & Seok, Jeongeum\\
 Collaborators: & 
 \end{tabular}
 \end{center}
Index: hw3.log
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) (preloaded format=pdflatex 2024.3.29)  5 APR 2024 14:13\r\nentering extended mode\r\n restricted \\write18 enabled.\r\n %&-line parsing enabled.\r\n**hw3.tex\r\n(./hw3.tex\r\nLaTeX2e <2023-11-01> patch level 1\r\nL3 programming layer <2024-03-14>\r\n(c:/texlive/2024/texmf-dist/tex/latex/base/article.cls\r\nDocument Class: article 2023/05/17 v1.4n Standard LaTeX document class\r\n(c:/texlive/2024/texmf-dist/tex/latex/base/size12.clo\r\nFile: size12.clo 2023/05/17 v1.4n Standard LaTeX file (size option)\r\n)\r\n\\c@part=\\count188\r\n\\c@section=\\count189\r\n\\c@subsection=\\count190\r\n\\c@subsubsection=\\count191\r\n\\c@paragraph=\\count192\r\n\\c@subparagraph=\\count193\r\n\\c@figure=\\count194\r\n\\c@table=\\count195\r\n\\abovecaptionskip=\\skip48\r\n\\belowcaptionskip=\\skip49\r\n\\bibindent=\\dimen140\r\n)\r\n(c:/texlive/2024/texmf-dist/tex/latex/base/inputenc.sty\r\nPackage: inputenc 2021/02/14 v1.3d Input encoding file\r\n\\inpenc@prehook=\\toks17\r\n\\inpenc@posthook=\\toks18\r\n)\r\n(c:/texlive/2024/texmf-dist/tex/latex/geometry/geometry.sty\r\nPackage: geometry 2020/01/02 v5.9 Page Geometry\r\n\r\n(c:/texlive/2024/texmf-dist/tex/latex/graphics/keyval.sty\r\nPackage: keyval 2022/05/29 v1.15 key=value parser (DPC)\r\n\\KV@toks@=\\toks19\r\n)\r\n(c:/texlive/2024/texmf-dist/tex/generic/iftex/ifvtex.sty\r\nPackage: ifvtex 2019/10/25 v1.7 ifvtex legacy package. Use iftex instead.\r\n\r\n(c:/texlive/2024/texmf-dist/tex/generic/iftex/iftex.sty\r\nPackage: iftex 2022/02/03 v1.0f TeX engine tests\r\n))\r\n\\Gm@cnth=\\count196\r\n\\Gm@cntv=\\count197\r\n\\c@Gm@tempcnt=\\count198\r\n\\Gm@bindingoffset=\\dimen141\r\n\\Gm@wd@mp=\\dimen142\r\n\\Gm@odd@mp=\\dimen143\r\n\\Gm@even@mp=\\dimen144\r\n\\Gm@layoutwidth=\\dimen145\r\n\\Gm@layoutheight=\\dimen146\r\n\\Gm@layouthoffset=\\dimen147\r\n\\Gm@layoutvoffset=\\dimen148\r\n\\Gm@dimlist=\\toks20\r\n)\r\n(c:/texlive/2024/texmf-dist/tex/latex/xcolor/xcolor.sty\r\nPackage: xcolor 2023/11/15 v3.01 LaTeX color extensions (UK)\r\n\r\n(c:/texlive/2024/texmf-dist/tex/latex/graphics-cfg/color.cfg\r\nFile: color.cfg 2016/01/02 v1.6 sample color configuration\r\n)\r\nPackage xcolor Info: Driver file: pdftex.def on input line 274.\r\n\r\n(c:/texlive/2024/texmf-dist/tex/latex/graphics-def/pdftex.def\r\nFile: pdftex.def 2022/09/22 v1.2b Graphics/color driver for pdftex\r\n)\r\n(c:/texlive/2024/texmf-dist/tex/latex/graphics/mathcolor.ltx)\r\nPackage xcolor Info: Model `cmy' substituted by `cmy0' on input line 1350.\r\nPackage xcolor Info: Model `hsb' substituted by `rgb' on input line 1354.\r\nPackage xcolor Info: Model `RGB' extended on input line 1366.\r\nPackage xcolor Info: Model `HTML' substituted by `rgb' on input line 1368.\r\nPackage xcolor Info: Model `Hsb' substituted by `hsb' on input line 1369.\r\nPackage xcolor Info: Model `tHsb' substituted by `hsb' on input line 1370.\r\nPackage xcolor Info: Model `HSB' substituted by `hsb' on input line 1371.\r\nPackage xcolor Info: Model `Gray' substituted by `gray' on input line 1372.\r\nPackage xcolor Info: Model `wave' substituted by `hsb' on input line 1373.\r\n)\r\n(c:/texlive/2024/texmf-dist/tex/latex/xcolor/svgnam.def\r\nFile: svgnam.def 2023/11/15 v3.01 Predefined colors according to SVG 1.1 (UK)\r\n)\r\n(c:/texlive/2024/texmf-dist/tex/latex/framed/framed.sty\r\nPackage: framed 2011/10/22 v 0.96: framed or shaded text with page breaks\r\n\\OuterFrameSep=\\skip50\r\n\\fb@frw=\\dimen149\r\n\\fb@frh=\\dimen150\r\n\\FrameRule=\\dimen151\r\n\\FrameSep=\\dimen152\r\n)\r\n(c:/texlive/2024/texmf-dist/tex/latex/url/url.sty\r\n\\Urlmuskip=\\muskip16\r\nPackage: url 2013/09/16  ver 3.4  Verb mode for urls, etc.\r\n)\r\n(c:/texlive/2024/texmf-dist/tex/latex/hyperref/hyperref.sty\r\nPackage: hyperref 2024-01-20 v7.01h Hypertext links for LaTeX\r\n\r\n(c:/texlive/2024/texmf-dist/tex/latex/kvsetkeys/kvsetkeys.sty\r\nPackage: kvsetkeys 2022-10-05 v1.19 Key value parser (HO)\r\n)\r\n(c:/texlive/2024/texmf-dist/tex/generic/kvdefinekeys/kvdefinekeys.sty\r\nPackage: kvdefinekeys 2019-12-19 v1.6 Define keys (HO)\r\n)\r\n(c:/texlive/2024/texmf-dist/tex/generic/pdfescape/pdfescape.sty\r\nPackage: pdfescape 2019/12/09 v1.15 Implements pdfTeX's escape features (HO)\r\n\r\n(c:/texlive/2024/texmf-dist/tex/generic/ltxcmds/ltxcmds.sty\r\nPackage: ltxcmds 2023-12-04 v1.26 LaTeX kernel commands for general use (HO)\r\n)\r\n(c:/texlive/2024/texmf-dist/tex/generic/pdftexcmds/pdftexcmds.sty\r\nPackage: pdftexcmds 2020-06-27 v0.33 Utility functions of pdfTeX for LuaTeX (HO\r\n)\r\n\r\n(c:/texlive/2024/texmf-dist/tex/generic/infwarerr/infwarerr.sty\r\nPackage: infwarerr 2019/12/03 v1.5 Providing info/warning/error messages (HO)\r\n)\r\nPackage pdftexcmds Info: \\pdf@primitive is available.\r\nPackage pdftexcmds Info: \\pdf@ifprimitive is available.\r\nPackage pdftexcmds Info: \\pdfdraftmode found.\r\n))\r\n(c:/texlive/2024/texmf-dist/tex/latex/hycolor/hycolor.sty\r\nPackage: hycolor 2020-01-27 v1.10 Color options for hyperref/bookmark (HO)\r\n)\r\n(c:/texlive/2024/texmf-dist/tex/latex/auxhook/auxhook.sty\r\nPackage: auxhook 2019-12-17 v1.6 Hooks for auxiliary files (HO)\r\n)\r\n(c:/texlive/2024/texmf-dist/tex/latex/hyperref/nameref.sty\r\nPackage: nameref 2023-11-26 v2.56 Cross-referencing by name of section\r\n\r\n(c:/texlive/2024/texmf-dist/tex/latex/refcount/refcount.sty\r\nPackage: refcount 2019/12/15 v3.6 Data extraction from label references (HO)\r\n)\r\n(c:/texlive/2024/texmf-dist/tex/generic/gettitlestring/gettitlestring.sty\r\nPackage: gettitlestring 2019/12/15 v1.6 Cleanup title references (HO)\r\n\r\n(c:/texlive/2024/texmf-dist/tex/latex/kvoptions/kvoptions.sty\r\nPackage: kvoptions 2022-06-15 v3.15 Key value format for package options (HO)\r\n))\r\n\\c@section@level=\\count199\r\n)\r\n(c:/texlive/2024/texmf-dist/tex/latex/etoolbox/etoolbox.sty\r\nPackage: etoolbox 2020/10/05 v2.5k e-TeX tools for LaTeX (JAW)\r\n\\etb@tempcnta=\\count266\r\n)\r\n\\@linkdim=\\dimen153\r\n\\Hy@linkcounter=\\count267\r\n\\Hy@pagecounter=\\count268\r\n\r\n(c:/texlive/2024/texmf-dist/tex/latex/hyperref/pd1enc.def\r\nFile: pd1enc.def 2024-01-20 v7.01h Hyperref: PDFDocEncoding definition (HO)\r\nNow handling font encoding PD1 ...\r\n... no UTF-8 mapping file for font encoding PD1\r\n)\r\n(c:/texlive/2024/texmf-dist/tex/generic/intcalc/intcalc.sty\r\nPackage: intcalc 2019/12/15 v1.3 Expandable calculations with integers (HO)\r\n)\r\n\\Hy@SavedSpaceFactor=\\count269\r\n\r\n(c:/texlive/2024/texmf-dist/tex/latex/hyperref/puenc.def\r\nFile: puenc.def 2024-01-20 v7.01h Hyperref: PDF Unicode definition (HO)\r\nNow handling font encoding PU ...\r\n... no UTF-8 mapping file for font encoding PU\r\n)\r\nPackage hyperref Info: Hyper figures OFF on input line 4179.\r\nPackage hyperref Info: Link nesting OFF on input line 4184.\r\nPackage hyperref Info: Hyper index ON on input line 4187.\r\nPackage hyperref Info: Plain pages OFF on input line 4194.\r\nPackage hyperref Info: Backreferencing OFF on input line 4199.\r\nPackage hyperref Info: Implicit mode ON; LaTeX internals redefined.\r\nPackage hyperref Info: Bookmarks ON on input line 4446.\r\n\\c@Hy@tempcnt=\\count270\r\nLaTeX Info: Redefining \\url on input line 4784.\r\n\\XeTeXLinkMargin=\\dimen154\r\n\r\n(c:/texlive/2024/texmf-dist/tex/generic/bitset/bitset.sty\r\nPackage: bitset 2019/12/09 v1.3 Handle bit-vector datatype (HO)\r\n\r\n(c:/texlive/2024/texmf-dist/tex/generic/bigintcalc/bigintcalc.sty\r\nPackage: bigintcalc 2019/12/15 v1.5 Expandable calculations on big integers (HO\r\n)\r\n))\r\n\\Fld@menulength=\\count271\r\n\\Field@Width=\\dimen155\r\n\\Fld@charsize=\\dimen156\r\nPackage hyperref Info: Hyper figures OFF on input line 6063.\r\nPackage hyperref Info: Link nesting OFF on input line 6068.\r\nPackage hyperref Info: Hyper index ON on input line 6071.\r\nPackage hyperref Info: backreferencing OFF on input line 6078.\r\nPackage hyperref Info: Link coloring OFF on input line 6083.\r\nPackage hyperref Info: Link coloring with OCG OFF on input line 6088.\r\nPackage hyperref Info: PDF/A mode OFF on input line 6093.\r\n\r\n(c:/texlive/2024/texmf-dist/tex/latex/base/atbegshi-ltx.sty\r\nPackage: atbegshi-ltx 2021/01/10 v1.0c Emulation of the original atbegshi\r\npackage with kernel methods\r\n)\r\n\\Hy@abspage=\\count272\r\n\\c@Item=\\count273\r\n\\c@Hfootnote=\\count274\r\n)\r\nPackage hyperref Info: Driver (autodetected): hpdftex.\r\n\r\n(c:/texlive/2024/texmf-dist/tex/latex/hyperref/hpdftex.def\r\nFile: hpdftex.def 2024-01-20 v7.01h Hyperref driver for pdfTeX\r\n\r\n(c:/texlive/2024/texmf-dist/tex/latex/base/atveryend-ltx.sty\r\nPackage: atveryend-ltx 2020/08/19 v1.0a Emulation of the original atveryend pac\r\nkage\r\nwith kernel methods\r\n)\r\n\\Fld@listcount=\\count275\r\n\\c@bookmark@seq@number=\\count276\r\n\r\n(c:/texlive/2024/texmf-dist/tex/latex/rerunfilecheck/rerunfilecheck.sty\r\nPackage: rerunfilecheck 2022-07-10 v1.10 Rerun checks for auxiliary files (HO)\r\n\r\n(c:/texlive/2024/texmf-dist/tex/generic/uniquecounter/uniquecounter.sty\r\nPackage: uniquecounter 2019/12/15 v1.4 Provide unlimited unique counter (HO)\r\n)\r\nPackage uniquecounter Info: New unique counter `rerunfilecheck' on input line 2\r\n85.\r\n)\r\n\\Hy@SectionHShift=\\skip51\r\n)\r\n(c:/texlive/2024/texmf-dist/tex/latex/listings/listings.sty\r\n\\lst@mode=\\count277\r\n\\lst@gtempboxa=\\box51\r\n\\lst@token=\\toks21\r\n\\lst@length=\\count278\r\n\\lst@currlwidth=\\dimen157\r\n\\lst@column=\\count279\r\n\\lst@pos=\\count280\r\n\\lst@lostspace=\\dimen158\r\n\\lst@width=\\dimen159\r\n\\lst@newlines=\\count281\r\n\\lst@lineno=\\count282\r\n\\lst@maxwidth=\\dimen160\r\n\r\n(c:/texlive/2024/texmf-dist/tex/latex/listings/lstpatch.sty\r\nFile: lstpatch.sty 2024/03/11 1.10a (Carsten Heinz)\r\n)\r\n(c:/texlive/2024/texmf-dist/tex/latex/listings/lstmisc.sty\r\nFile: lstmisc.sty 2024/03/11 1.10a (Carsten Heinz)\r\n\\c@lstnumber=\\count283\r\n\\lst@skipnumbers=\\count284\r\n\\lst@framebox=\\box52\r\n)\r\n(c:/texlive/2024/texmf-dist/tex/latex/listings/listings.cfg\r\nFile: listings.cfg 2024/03/11 1.10a listings configuration\r\n))\r\nPackage: listings 2024/03/11 1.10a (Carsten Heinz)\r\n\r\n(c:/texlive/2024/texmf-dist/tex/latex/float/float.sty\r\nPackage: float 2001/11/08 v1.3d Float enhancements (AL)\r\n\\c@float@type=\\count285\r\n\\float@exts=\\toks22\r\n\\float@box=\\box53\r\n\\@float@everytoks=\\toks23\r\n\\@floatcapt=\\box54\r\n)\r\n(c:/texlive/2024/texmf-dist/tex/latex/graphics/graphicx.sty\r\nPackage: graphicx 2021/09/16 v1.2d Enhanced LaTeX Graphics (DPC,SPQR)\r\n\r\n(c:/texlive/2024/texmf-dist/tex/latex/graphics/graphics.sty\r\nPackage: graphics 2022/03/10 v1.4e Standard LaTeX Graphics (DPC,SPQR)\r\n\r\n(c:/texlive/2024/texmf-dist/tex/latex/graphics/trig.sty\r\nPackage: trig 2021/08/11 v1.11 sin cos tan (DPC)\r\n)\r\n(c:/texlive/2024/texmf-dist/tex/latex/graphics-cfg/graphics.cfg\r\nFile: graphics.cfg 2016/06/04 v1.11 sample graphics configuration\r\n)\r\nPackage graphics Info: Driver file: pdftex.def on input line 107.\r\n)\r\n\\Gin@req@height=\\dimen161\r\n\\Gin@req@width=\\dimen162\r\n)\r\n(c:/texlive/2024/texmf-dist/tex/latex/sectsty/sectsty.sty\r\nPackage: sectsty 2002/02/25 v2.0.2 Commands to change all sectional heading sty\r\nles\r\n\r\n\r\nLaTeX Warning: Command \\underbar  has changed.\r\n               Check if current package is valid.\r\n\r\n\r\nLaTeX Warning: Command \\underline  has changed.\r\n               Check if current package is valid.\r\n\r\n) (c:/texlive/2024/texmf-dist/tex/latex/titlesec/titlesec.sty\r\nPackage: titlesec 2023/10/27 v2.16 Sectioning titles\r\n\\ttl@box=\\box55\r\n\\beforetitleunit=\\skip52\r\n\\aftertitleunit=\\skip53\r\n\\ttl@plus=\\dimen163\r\n\\ttl@minus=\\dimen164\r\n\\ttl@toksa=\\toks24\r\n\\titlewidth=\\dimen165\r\n\\titlewidthlast=\\dimen166\r\n\\titlewidthfirst=\\dimen167\r\n)\r\n(c:/texlive/2024/texmf-dist/tex/latex/enumitem/enumitem.sty\r\nPackage: enumitem 2019/06/20 v3.9 Customized lists\r\n\\labelindent=\\skip54\r\n\\enit@outerparindent=\\dimen168\r\n\\enit@toks=\\toks25\r\n\\enit@inbox=\\box56\r\n\\enit@count@id=\\count286\r\n\\enitdp@description=\\count287\r\n)\r\n(c:/texlive/2024/texmf-dist/tex/latex/amsfonts/amssymb.sty\r\nPackage: amssymb 2013/01/14 v3.01 AMS font symbols\r\n\r\n(c:/texlive/2024/texmf-dist/tex/latex/amsfonts/amsfonts.sty\r\nPackage: amsfonts 2013/01/14 v3.01 Basic AMSFonts support\r\n\\@emptytoks=\\toks26\r\n\\symAMSa=\\mathgroup4\r\n\\symAMSb=\\mathgroup5\r\nLaTeX Font Info:    Redeclaring math symbol \\hbar on input line 98.\r\nLaTeX Font Info:    Overwriting math alphabet `\\mathfrak' in version `bold'\r\n(Font)                  U/euf/m/n --> U/euf/b/n on input line 106.\r\n))\r\nPackage hyperref Info: Option `colorlinks' set `true' on input line 26.\r\n\r\n(c:/texlive/2024/texmf-dist/tex/latex/tex-gyre/tgpagella.sty\r\nPackage: tgpagella 2009/09/27 v1.2 TeX Gyre Pagella as default roman family\r\n)\r\nLaTeX Font Info:    Trying to load font information for OT1+qpl on input line 5\r\n6.\r\n\r\n(c:/texlive/2024/texmf-dist/tex/latex/tex-gyre/ot1qpl.fd\r\nFile: ot1qpl.fd 2009/09/25 v1.2 font definition file for OT1/qpl\r\n)\r\n(c:/texlive/2024/texmf-dist/tex/latex/l3backend/l3backend-pdftex.def\r\nFile: l3backend-pdftex.def 2024-03-14 L3 backend support: PDF output (pdfTeX)\r\n\\l__color_backend_stack_int=\\count288\r\n\\l__pdf_internal_box=\\box57\r\n)\r\nNo file hw3.aux.\r\n\\openout1 = `hw3.aux'.\r\n\r\nLaTeX Font Info:    Checking defaults for OML/cmm/m/it on input line 56.\r\nLaTeX Font Info:    ... okay on input line 56.\r\nLaTeX Font Info:    Checking defaults for OMS/cmsy/m/n on input line 56.\r\nLaTeX Font Info:    ... okay on input line 56.\r\nLaTeX Font Info:    Checking defaults for OT1/cmr/m/n on input line 56.\r\nLaTeX Font Info:    ... okay on input line 56.\r\nLaTeX Font Info:    Checking defaults for T1/cmr/m/n on input line 56.\r\nLaTeX Font Info:    ... okay on input line 56.\r\nLaTeX Font Info:    Checking defaults for TS1/cmr/m/n on input line 56.\r\nLaTeX Font Info:    ... okay on input line 56.\r\nLaTeX Font Info:    Checking defaults for OMX/cmex/m/n on input line 56.\r\nLaTeX Font Info:    ... okay on input line 56.\r\nLaTeX Font Info:    Checking defaults for U/cmr/m/n on input line 56.\r\nLaTeX Font Info:    ... okay on input line 56.\r\nLaTeX Font Info:    Checking defaults for PD1/pdf/m/n on input line 56.\r\nLaTeX Font Info:    ... okay on input line 56.\r\nLaTeX Font Info:    Checking defaults for PU/pdf/m/n on input line 56.\r\nLaTeX Font Info:    ... okay on input line 56.\r\n*geometry* driver: auto-detecting\r\n*geometry* detected driver: pdftex\r\n*geometry* verbose mode - [ preamble ] result:\r\n* driver: pdftex\r\n* paper: <default>\r\n* layout: <same size as paper>\r\n* layoutoffset:(h,v)=(0.0pt,0.0pt)\r\n* modes: \r\n* h-part:(L,W,R)=(72.26999pt, 469.75502pt, 72.26999pt)\r\n* v-part:(T,H,B)=(72.26999pt, 650.43001pt, 72.26999pt)\r\n* \\paperwidth=614.295pt\r\n* \\paperheight=794.96999pt\r\n* \\textwidth=469.75502pt\r\n* \\textheight=650.43001pt\r\n* \\oddsidemargin=0.0pt\r\n* \\evensidemargin=0.0pt\r\n* \\topmargin=-37.0pt\r\n* \\headheight=12.0pt\r\n* \\headsep=25.0pt\r\n* \\topskip=12.0pt\r\n* \\footskip=30.0pt\r\n* \\marginparwidth=44.0pt\r\n* \\marginparsep=10.0pt\r\n* \\columnsep=10.0pt\r\n* \\skip\\footins=10.8pt plus 4.0pt minus 2.0pt\r\n* \\hoffset=0.0pt\r\n* \\voffset=0.0pt\r\n* \\mag=1000\r\n* \\@twocolumnfalse\r\n* \\@twosidefalse\r\n* \\@mparswitchfalse\r\n* \\@reversemarginfalse\r\n* (1in=72.27pt=25.4mm, 1cm=28.453pt)\r\n\r\n(c:/texlive/2024/texmf-dist/tex/context/base/mkii/supp-pdf.mkii\r\n[Loading MPS to PDF converter (version 2006.09.02).]\r\n\\scratchcounter=\\count289\r\n\\scratchdimen=\\dimen169\r\n\\scratchbox=\\box58\r\n\\nofMPsegments=\\count290\r\n\\nofMParguments=\\count291\r\n\\everyMPshowfont=\\toks27\r\n\\MPscratchCnt=\\count292\r\n\\MPscratchDim=\\dimen170\r\n\\MPnumerator=\\count293\r\n\\makeMPintoPDFobject=\\count294\r\n\\everyMPtoPDFconversion=\\toks28\r\n) (c:/texlive/2024/texmf-dist/tex/latex/epstopdf-pkg/epstopdf-base.sty\r\nPackage: epstopdf-base 2020-01-24 v2.11 Base part for package epstopdf\r\nPackage epstopdf-base Info: Redefining graphics rule for `.eps' on input line 4\r\n85.\r\n\r\n(c:/texlive/2024/texmf-dist/tex/latex/latexconfig/epstopdf-sys.cfg\r\nFile: epstopdf-sys.cfg 2010/07/13 v1.3 Configuration of (r)epstopdf for TeX Liv\r\ne\r\n))\r\nPackage hyperref Info: Link coloring ON on input line 56.\r\n\\@outlinefile=\\write3\r\n\\openout3 = `hw3.out'.\r\n\r\n\\c@lstlisting=\\count295\r\nLaTeX Font Info:    Trying to load font information for U+msa on input line 64.\r\n\r\n\r\n(c:/texlive/2024/texmf-dist/tex/latex/amsfonts/umsa.fd\r\nFile: umsa.fd 2013/01/14 v3.01 AMS symbols A\r\n)\r\nLaTeX Font Info:    Trying to load font information for U+msb on input line 64.\r\n\r\n\r\n(c:/texlive/2024/texmf-dist/tex/latex/amsfonts/umsb.fd\r\nFile: umsb.fd 2013/01/14 v3.01 AMS symbols B\r\n)\r\nLaTeX Font Info:    Trying to load font information for TS1+qpl on input line 8\r\n4.\r\n\r\n(c:/texlive/2024/texmf-dist/tex/latex/tex-gyre/ts1qpl.fd\r\nFile: ts1qpl.fd 2009/09/25 v1.2 font definition file for TS1/qpl\r\n) [1\r\n\r\n{c:/texlive/2024/texmf-var/fonts/map/pdftex/updmap/pdftex.map}{c:/texlive/2024/\r\ntexmf-dist/fonts/enc/dvips/tex-gyre/q-rm.enc}{c:/texlive/2024/texmf-dist/fonts/\r\nenc/dvips/tex-gyre/q-ts1.enc}]\r\nLaTeX Font Info:    Trying to load font information for OMS+cmtt on input line \r\n108.\r\nLaTeX Font Info:    No file OMScmtt.fd. on input line 108.\r\n\r\n\r\nLaTeX Font Warning: Font shape `OMS/cmtt/m/n' undefined\r\n(Font)              using `OMS/cmsy/m/n' instead\r\n(Font)              for symbol `textbraceleft' on input line 108.\r\n\r\n\r\nOverfull \\hbox (10.3949pt too wide) in paragraph at lines 112--113\r\n[]\\OT1/cmtt/m/n/12 Mary went back to the office. John went to the bathroom. Whe\r\nre is Mary?\r\n []\r\n\r\n[2]\r\nOverfull \\hbox (31.30457pt too wide) in paragraph at lines 123--124\r\n\\OT1/cmtt/m/n/12 get[]acc\\OT1/qpl/m/n/12 . You only need to com-plete the loss/\r\nac-cu-racy cal-cu-la-tions un-der \\OT1/cmtt/m/n/12 if logits.dim()\r\n []\r\n\r\n\r\nOverfull \\hbox (13.766pt too wide) in paragraph at lines 126--127\r\n[]\\OT1/cmtt/m/n/10.95 python3 ft.py --task ft --model bert-tiny,bert-med --data\r\nset amazon --k 1,8,128 \r\n []\r\n\r\n\r\nOverfull \\hbox (25.26338pt too wide) in paragraph at lines 134--135\r\n[]\\OT1/cmtt/m/n/10.95 python3 ft.py --task plot --model bert-tiny,bert-med --da\r\ntaset amazon --k 1,8,128 \r\n []\r\n\r\n[3]\r\nLaTeX Font Info:    Trying to load font information for OML+cmtt on input line \r\n155.\r\nLaTeX Font Info:    No file OMLcmtt.fd. on input line 155.\r\n\r\n\r\nLaTeX Font Warning: Font shape `OML/cmtt/m/n' undefined\r\n(Font)              using `OML/cmm/m/it' instead\r\n(Font)              for symbol `textless' on input line 155.\r\n\r\n\r\nOverfull \\hbox (18.07022pt too wide) in paragraph at lines 160--161\r\n[]\\OT1/cmtt/m/n/12 Who is the US president? Joe Biden What is earth's tallest m\r\nountain? Mount... \r\n []\r\n\r\n[4]\r\n\r\nLaTeX Font Warning: Font shape `OT1/cmtt/b/n' undefined\r\n(Font)              using `OT1/cmtt/m/n' instead on input line 185.\r\n\r\n[5] [6]\r\nOverfull \\hbox (7.6132pt too wide) in paragraph at lines 240--241\r\n[]\\OT1/qpl/m/n/12 Implement batch con-struc-tion for fine-tuning GPT-2 in func-\r\ntion \\OT1/cmtt/m/n/12 ft.py:tokenize[]\r\n []\r\n\r\n\r\nOverfull \\hbox (1.99495pt too wide) in paragraph at lines 252--253\r\n[]\\OT1/cmtt/m/n/10.95 python3 ft.py --task plot --model med --mode first,last,m\r\niddle,lora4,lora16 \\OMS/cmtt/m/n/10.95 n \r\n []\r\n\r\n\r\nOverfull \\hbox (1.99495pt too wide) in paragraph at lines 255--256\r\n[]\\OT1/cmtt/m/n/10.95 python3 ft.py --task plot --model med --mode first,last,m\r\niddle,lora4,lora16 \\OMS/cmtt/m/n/10.95 n \r\n []\r\n\r\n[7]\r\nOverfull \\hbox (0.67444pt too wide) in paragraph at lines 268--269\r\n[]\\OT1/qpl/m/n/12 When does in-context learn-ing seem like the bet-ter choice, \r\nwith re-spect to the amount\r\n []\r\n\r\n[8] (./hw3.aux)\r\n ***********\r\nLaTeX2e <2023-11-01> patch level 1\r\nL3 programming layer <2024-03-14>\r\n ***********\r\n\r\n\r\nLaTeX Font Warning: Some font shapes were not available, defaults substituted.\r\n\r\n\r\nPackage rerunfilecheck Warning: File `hw3.out' has changed.\r\n(rerunfilecheck)                Rerun to get outlines right\r\n(rerunfilecheck)                or use package `bookmark'.\r\n\r\nPackage rerunfilecheck Info: Checksums for `hw3.out':\r\n(rerunfilecheck)             Before: <no file>\r\n(rerunfilecheck)             After:  D41D8CD98F00B204E9800998ECF8427E;0.\r\n ) \r\nHere is how much of TeX's memory you used:\r\n 12392 strings out of 474104\r\n 187775 string characters out of 5747502\r\n 1937496 words of memory out of 5000000\r\n 34568 multiletter control sequences out of 15000+600000\r\n 602733 words of font info for 82 fonts, out of 8000000 for 9000\r\n 1141 hyphenation exceptions out of 8191\r\n 75i,8n,79p,966b,792s stack positions out of 10000i,1000n,20000p,200000b,200000s\r\n<c:/texlive/2024/texmf-dist/fonts/type1/public/amsfonts/cm/cmbx12.pfb><c:/tex\r\nlive/2024/texmf-dist/fonts/type1/public/amsfonts/cm/cmex10.pfb><c:/texlive/2024\r\n/texmf-dist/fonts/type1/public/amsfonts/cm/cmmi12.pfb><c:/texlive/2024/texmf-di\r\nst/fonts/type1/public/amsfonts/cm/cmmi8.pfb><c:/texlive/2024/texmf-dist/fonts/t\r\nype1/public/amsfonts/cm/cmr12.pfb><c:/texlive/2024/texmf-dist/fonts/type1/publi\r\nc/amsfonts/cm/cmr6.pfb><c:/texlive/2024/texmf-dist/fonts/type1/public/amsfonts/\r\ncm/cmr8.pfb><c:/texlive/2024/texmf-dist/fonts/type1/public/amsfonts/cm/cmsy10.p\r\nfb><c:/texlive/2024/texmf-dist/fonts/type1/public/amsfonts/cm/cmsy8.pfb><c:/tex\r\nlive/2024/texmf-dist/fonts/type1/public/amsfonts/cm/cmtt10.pfb><c:/texlive/2024\r\n/texmf-dist/fonts/type1/public/amsfonts/cm/cmtt12.pfb><c:/texlive/2024/texmf-di\r\nst/fonts/type1/public/amsfonts/symbols/msbm10.pfb><c:/texlive/2024/texmf-dist/f\r\nonts/type1/public/tex-gyre/qplb.pfb><c:/texlive/2024/texmf-dist/fonts/type1/pub\r\nlic/tex-gyre/qplbi.pfb><c:/texlive/2024/texmf-dist/fonts/type1/public/tex-gyre/\r\nqplr.pfb><c:/texlive/2024/texmf-dist/fonts/type1/public/tex-gyre/qplri.pfb>\r\nOutput written on hw3.pdf (8 pages, 359378 bytes).\r\nPDF statistics:\r\n 185 PDF objects out of 1000 (max. 8388607)\r\n 140 compressed objects within 2 object streams\r\n 41 named destinations out of 1000 (max. 500000)\r\n 1 words of extra memory for PDF output out of 10000 (max. 10000000)\r\n\r\n
===================================================================
diff --git a/hw3.log b/hw3.log
--- a/hw3.log	
+++ b/hw3.log	
@@ -1,4 +1,4 @@
-This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) (preloaded format=pdflatex 2024.3.29)  5 APR 2024 14:13
+This is pdfTeX, Version 3.141592653-2.6-1.40.26 (TeX Live 2024) (preloaded format=pdflatex 2024.3.29)  30 APR 2024 16:54
 entering extended mode
  restricted \write18 enabled.
  %&-line parsing enabled.
@@ -335,7 +335,7 @@
 \l__color_backend_stack_int=\count288
 \l__pdf_internal_box=\box57
 )
-No file hw3.aux.
+(./hw3.aux)
 \openout1 = `hw3.aux'.
 
 LaTeX Font Info:    Checking defaults for OML/cmm/m/it on input line 56.
@@ -356,6 +356,7 @@
 LaTeX Font Info:    ... okay on input line 56.
 LaTeX Font Info:    Checking defaults for PU/pdf/m/n on input line 56.
 LaTeX Font Info:    ... okay on input line 56.
+
 *geometry* driver: auto-detecting
 *geometry* detected driver: pdftex
 *geometry* verbose mode - [ preamble ] result:
@@ -413,14 +414,14 @@
 e
 ))
 Package hyperref Info: Link coloring ON on input line 56.
+ (./hw3.out) (./hw3.out)
 \@outlinefile=\write3
 \openout3 = `hw3.out'.
 
 \c@lstlisting=\count295
 LaTeX Font Info:    Trying to load font information for U+msa on input line 64.
 
-
-(c:/texlive/2024/texmf-dist/tex/latex/amsfonts/umsa.fd
+ (c:/texlive/2024/texmf-dist/tex/latex/amsfonts/umsa.fd
 File: umsa.fd 2013/01/14 v3.01 AMS symbols A
 )
 LaTeX Font Info:    Trying to load font information for U+msb on input line 64.
@@ -526,20 +527,14 @@
 
 LaTeX Font Warning: Some font shapes were not available, defaults substituted.
 
-
-Package rerunfilecheck Warning: File `hw3.out' has changed.
-(rerunfilecheck)                Rerun to get outlines right
-(rerunfilecheck)                or use package `bookmark'.
-
-Package rerunfilecheck Info: Checksums for `hw3.out':
-(rerunfilecheck)             Before: <no file>
-(rerunfilecheck)             After:  D41D8CD98F00B204E9800998ECF8427E;0.
+Package rerunfilecheck Info: File `hw3.out' has not changed.
+(rerunfilecheck)             Checksum: D41D8CD98F00B204E9800998ECF8427E;0.
  ) 
 Here is how much of TeX's memory you used:
- 12392 strings out of 474104
- 187775 string characters out of 5747502
- 1937496 words of memory out of 5000000
- 34568 multiletter control sequences out of 15000+600000
+ 12400 strings out of 474104
+ 187863 string characters out of 5747502
+ 1938496 words of memory out of 5000000
+ 34570 multiletter control sequences out of 15000+600000
  602733 words of font info for 82 fonts, out of 8000000 for 9000
  1141 hyphenation exceptions out of 8191
  75i,8n,79p,966b,792s stack positions out of 10000i,1000n,20000p,200000b,200000s
@@ -557,7 +552,7 @@
 onts/type1/public/tex-gyre/qplb.pfb><c:/texlive/2024/texmf-dist/fonts/type1/pub
 lic/tex-gyre/qplbi.pfb><c:/texlive/2024/texmf-dist/fonts/type1/public/tex-gyre/
 qplr.pfb><c:/texlive/2024/texmf-dist/fonts/type1/public/tex-gyre/qplri.pfb>
-Output written on hw3.pdf (8 pages, 359378 bytes).
+Output written on hw3.pdf (8 pages, 359568 bytes).
 PDF statistics:
  185 PDF objects out of 1000 (max. 8388607)
  140 compressed objects within 2 object streams
Index: .idea/hw3-2022-code.iml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\r\n<module type=\"PYTHON_MODULE\" version=\"4\">\r\n  <component name=\"NewModuleRootManager\">\r\n    <content url=\"file://$MODULE_DIR$\">\r\n      <excludeFolder url=\"file://$MODULE_DIR$/venv\" />\r\n    </content>\r\n    <orderEntry type=\"inheritedJdk\" />\r\n    <orderEntry type=\"sourceFolder\" forTests=\"false\" />\r\n  </component>\r\n  <component name=\"PyDocumentationSettings\">\r\n    <option name=\"format\" value=\"GOOGLE\" />\r\n    <option name=\"myDocStringFormat\" value=\"Google\" />\r\n  </component>\r\n</module>
===================================================================
diff --git a/.idea/hw3-2022-code.iml b/.idea/hw3-2022-code.iml
--- a/.idea/hw3-2022-code.iml	
+++ b/.idea/hw3-2022-code.iml	
@@ -2,9 +2,10 @@
 <module type="PYTHON_MODULE" version="4">
   <component name="NewModuleRootManager">
     <content url="file://$MODULE_DIR$">
+      <excludeFolder url="file://$MODULE_DIR$/.venv" />
       <excludeFolder url="file://$MODULE_DIR$/venv" />
     </content>
-    <orderEntry type="inheritedJdk" />
+    <orderEntry type="jdk" jdkName="Python 3.10 (hw3-2022-code)" jdkType="Python SDK" />
     <orderEntry type="sourceFolder" forTests="false" />
   </component>
   <component name="PyDocumentationSettings">
